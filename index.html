<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A novel neural rendering-based framework with a novel joint geometry-appearance prior to achieve text-to-3D-portrait generation.">
  <meta name="keywords" content="3D portrait generation, 3D-aware GANs, diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generative Human Geometry Distribution</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/1f47b.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
            .text-color-gradient {
                display: inline-block;
                font-size: 10em;
                font-weight: 700;
                background: linear-gradient(120deg, #a6c0fe 0%, #f68084 100%);
                background-clip: text;
                -webkit-background-clip: text;
                color: transparent;
            }
          .card {
            background: #DFD3C3;
            transition: 0.3s;
            border-radius: 12px;
            margin: 0px 5px 10px 5px;
            padding:10px 20px 20px 20px
            }

            .container {
              padding: -12px -16px;
            }
        </style>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://onethousandwu.com">
      <span class="icon">
          <img src="static/images/me.png">
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
            <a class="navbar-item" href="https://onethousandwu.com/3DPortraitGAN.github.io/">
                3DPortraitGAN
            </a>
          <a class="navbar-item" href="https://onethousandwu.com/LPFF.github.io/">
            LPFF
          </a>
          <a class="navbar-item" href="https://onethousandwu.com/HairMapper.github.io/">
            HairMapper
          </a>
          <a class="navbar-item" href="https://onethousandwu.com/doublechinremoval.github.io/">
            DoubleChin removal
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div class="text-color-gradient title is-1 publication-title"> <span class="dnerf">Generative Human Geometry Distribution</span>  </div>
          <!-- <h1 class="title is-2 publication-title" >  Generative Human Geometry Distribution</h1> -->
          <div class="is-size-3 publication-conf">

            <span><b>Under review </b></span>
            </div>
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://onethousandwu.com/">Yiqian Wu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://xh38.github.io/">Hao Xu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yuyujunjun.github.io/">Xiangjun Tang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://vision.cs.yale.edu/members/xien-chen.html">Xien Chen</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://inf.ethz.ch/people/person-detail.MjYyNzgw.TGlzdC8zMDQsLTg3NDc3NjI0MQ==.html">Siyu Tang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a>Zhebin Zhang</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a>Chen Li</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.cad.zju.edu.cn/home/jin/">Xiaogang Jin*</a><sup>1</sup>
            </span>
          </div> -->

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>State Key Lab of CAD&CG, Zhejiang University,</span>
            <span class="author-block"><sup>2</sup>Yale University,</span>
            <span class="author-block"><sup>3</sup>ETH ZÃ¼rich,</span>
            <span class="author-block"><sup>4</sup>OPPO US Research Center</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
             <!-- <span class="link-block"> 
               <a href="https://dl.acm.org/doi/10.1145/3658162"
                  class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                     <i class="fas fa-file-pdf"></i>
                 </span>
                 <span>Paper (ACM Digital Library)</span>
               </a>
           </span>  -->

              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2404.10394"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>ArXiv</span>
                </a>
              </span> -->

              <!-- <span class="link-block">
                <a href="https://drive.google.com/file/d/1LasG-urCA7rEoITHofBwEk0CloXM0DwX/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Suppl</span>
                </a>
              </span> -->

              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://youtu.be/z7xWiD1p1_4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/oneThousand1000/Portrait3D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://huggingface.co/datasets/onethousand/Portrait3D_gallery"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Results</span>
                  </a>
                </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-4">
    <div class="hero-body">
       <img src="./static/images/teaser.png" alt="Pipeline">
      <h2 class="subtitle has-text-centered">
        (a) Given a human pose, we randomly synthesize realistic geometry with natural clothing details. (b) Given a normal image, we synthesize high-quality geometry in novel poses. All visual results are rendered from point clouds.
      </h2>
    </div>
  </div>


  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Realistic human geometry generation is an important yet challenging task, requiring both the preservation of fine clothing details and the accurate modeling of clothing-pose interactions. 
Geometry distributions, which can model the geometry of a single human as a distribution, provide a promising representation for high-fidelity synthesis. However, applying geometry distributions for human generation requires learning a dataset-level distribution over numerous individual geometry distributions. To address the resulting challenges, we propose a novel 3D human generative framework that, for the first time, models the distribution of human geometry distributions. Our framework operates in two stages: first, generating the human geometry distribution, and second, synthesizing high-fidelity humans by sampling from this distribution. 
We validate our method on two tasks: pose-conditioned 3D human generation and single-view-based novel pose generation. 
Experimental results demonstrate that our approach achieves the best quantitative results in terms of realism and geometric fidelity, outperforming state-of-the-art generative methods.
          </p>
        </div>
      </div>
    </div>

  <div class="container is-4">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/denoising.mp4"
                type="video/mp4">
      </video>

      <h2 class="subtitle has-text-centered">
        (a) Our method enables infinite sampling to synthesize high-fidelity geometry.<br>
        (b) We obtain the realistic human shape by a denoising progress.
      </h2>
    </div>
  </div>



    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>
        <div class="content has-text-justified">
          <div class="video-item">
            <video poster="" id="399-video" autoplay controls muted loop playsinline>
              <source src="./static/videos/animation.mp4" type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Pose-conditioned Random Generation</h2>
        <div class="content has-text-justified">
          <div class="teaser_video">
            <video id="pose_gen" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/pose_gen.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Pose-aware Novel Pose Generation</h2>
        <div class="content has-text-justified">
          <div class="teaser_video">
            <video poster="" id="399-video" autoplay controls muted loop playsinline>
              <source src="./static/videos/novel_pose1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="teaser_video">
            <video poster="" id="355-video" autoplay controls muted loop playsinline>
              <source src="./static/videos/novel_pose2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="teaser_video">
            <video poster="" id="359-video" autoplay controls muted loop playsinline>
              <source src="./static/videos/novel_pose3.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
</section>
       


    <!--/ Pipeline. -->

       <!-- Comparison. -->

    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison</h2>
        <div class="content has-text-justified">
          <p>
            Qualitative comparison to SOTA text-to-3D approaches: <a href="https://dreamfusion3d.github.io/">DreamFusion</a>,  <a href="https://github.com/luciddreamer-cvlab/LucidDreamer">LucidDreamer</a>,
            <a href="https://github.com/TingtingLiao/TADA">TADA</a>, <a href="https://github.com/songrise/AvatarCraft">AvatarCraft</a>, <a href="https://github.com/magic-research/avatarstudio">AvatarStudio</a>, <a href="https://github.com/alvinliu0/HumanGaussian">HumanGaussian</a>, <a href="https://github.com/bytedance/AvatarVerse">AvatarVerse</a>, <a href="https://github.com/xhuangcv/humannorm">HumanNorm</a>,
            <a href="https://seeavatar3d.github.io/">SEEAvatar</a>, <a href="https://github.com/HaoZhang990127/TECA">TECA</a>, and our method. The input prompt is presented at the top.
          </p>
          <figure class="image">
            <img src="./static/images/Comparison.png" alt="Comparison">
          </figure>
        </div>

        <div class="content has-text-justified">
          <p>
            Qualitative comparison to SOTA diffusion-based reconstruction approaches: <a href="https://github.com/One-2-3-45/One-2-3-45">One-2-3-45</a>,
            <a href="https://github.com/dreamgaussian/dreamgaussian">DreamGaussian</a>, <a href="https://github.com/xxlong0/Wonder3D">Wonder3D</a>, <a href="https://github.com/liuyuan-pal/SyncDreamer">SyncDreamer</a> and <a href="https://github.com/huangyangyi/TeCH">TeCH</a>, and our method. The reference prompt
            is presented at the top, and the reference image (which is also the generated image
            used for image inversion in our framework) is presented at the left.
          </p>
          <figure class="image">
            <img src="./static/images/comparison_reconstruct.png" alt="comparison_reconstruct">
          </figure>
        </div>


      </div>
      </div> -->


  </div>

  <!-- Comparison. -->

    <!-- Results Gallery. -->

    <!-- <div class="columns is-centered">
      <div class="column is-5">
        <h2 class="title is-3">Results Gallery</h2>
        <div class="content has-text-justified">
          <p>
            We offer a gallery of 300 3D portraits (with their corresponding prompts)
            generated by our method, all viewable and accessible on <a href="https://huggingface.co/datasets/onethousand/Portrait3D_gallery">huggingface</a>.
            For visualization, please refer to our <a href="https://github.com/oneThousand1000/Portrait3D">github repository</a>.
            (Bellow are some examples of the generated 3D portraits.)
          </p>
          <figure class="image">
            <img src="./static/images/results.png" alt="Pipeline">
          </figure>
        </div>
      </div>
</div> -->


    <!--/ Pipeline. -->


</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">



    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">

          <a href="https://arxiv.org/abs/2307.14770">3DPortraitGAN</a> is a 3D-aware generator capable
          of generating 3D full-head avatars, and can function as a prior for 3D portrait generation.
          We use 3DPortraitGAN as a prior in our method, and make a significant improvement in the
          underlying 3D representation. Please refer to our paper for more details.
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->
<!-- 
   </div>
  </div> -->


</section> -->


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    If you find this project helpful to your research, please consider citing:
    <pre><code>@article{Portrait3D_sig24,
author = {Wu, Yiqian and Xu, Hao and Tang, Xiangjun and Chen, Xien and Tang, Siyun and Zhang, Zhebin and Li, Chen and Jin, Xiaogang},
title = {Portrait3D: Text-Guided High-Quality 3D Portrait Generation Using Pyramid Representation and GANs Prior},
year = {2024},
publisher = {Association for Computing Machinery},
volume = {43},
number = {4},
url = {https://doi.org/10.1145/3658162},
doi = {10.1145/3658162},
journal = {ACM Trans. Graph.},
month = {Jul},
articleno = {45}
}
</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
           This page is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">the Nerfies website</a>. We thank the authors for sharing it.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
